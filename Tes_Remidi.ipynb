{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xVcFIY2LVVNE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n",
        "from tensorflow.keras.layers import Dense,Conv2D,GlobalAvgPool2D,Input\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras import callbacks,optimizers\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQl1x1cDWuih",
        "outputId": "c0298112-52fe-4619-d22b-2b72d0b37a22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/animal_classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ogGIGF8XL-W",
        "outputId": "7c0ce917-165d-4637-9a10-4b2a9226b459"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/animal_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import translate\n",
        "translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3vRFsh9yHj",
        "outputId": "f37013c5-ccd3-4149-f91e-382d888d6b6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cane': 'dog',\n",
              " 'cavallo': 'horse',\n",
              " 'elefante': 'elephant',\n",
              " 'farfalla': 'butterfly',\n",
              " 'gallina': 'chicken',\n",
              " 'gatto': 'cat',\n",
              " 'mucca': 'cow',\n",
              " 'pecora': 'sheep',\n",
              " 'scoiattolo': 'squirrel',\n",
              " 'dog': 'cane',\n",
              " 'elephant': 'elefante',\n",
              " 'butterfly': 'farfalla',\n",
              " 'chicken': 'gallina',\n",
              " 'cat': 'gatto',\n",
              " 'cow': 'mucca',\n",
              " 'spider': 'ragno',\n",
              " 'squirrel': 'scoiattolo'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"raw-img\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYvuF6t__d0Z",
        "outputId": "134e0719-c2c9-492c-a88f-321933c9fa1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cane',\n",
              " 'cavallo',\n",
              " 'elefante',\n",
              " 'farfalla',\n",
              " 'gallina',\n",
              " 'gatto',\n",
              " 'mucca',\n",
              " 'pecora',\n",
              " 'ragno',\n",
              " 'scoiattolo']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(\"raw-img\"):\n",
        "  print(i,len(os.listdir(\"raw-img/\"+i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VvYvrHYBVLj",
        "outputId": "67dd1564-d453-4112-dfe2-5347182be38d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog 4863\n",
            "horse 2623\n",
            "elephant 1446\n",
            "butterfly 2112\n",
            "chicken 3098\n",
            "cat 1668\n",
            "cow 912\n",
            "sheep 0\n",
            "spider 0\n",
            "squirrel 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"train\")\n",
        "  os.mkdir(\"test\")\n",
        "except:\n",
        "  pass\n",
        "for i in os.listdir(\"raw-img\"):\n",
        "  try:\n",
        "    os.mkdir(\"train/\"+i)\n",
        "    os.mkdir(\"test/\"+i)\n",
        "  except:\n",
        "    pass\n",
        "  for j in os.listdir(\"raw-img/\"+i)[:1000]:\n",
        "    os.rename(\"raw-img/\"+i+\"/\"+j,\"train/\"+i+\"/\"+j)\n",
        "  for j in os.listdir(\"raw-img/\"+i)[:400]:\n",
        "    os.rename(\"raw-img/\"+i+\"/\"+j,\"test/\"+i+\"/\"+j)"
      ],
      "metadata": {
        "id": "n68G54zLDWaZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_Data(dir_path,target_size,batch,class_lst,preporcssing,):\n",
        "  if preporcssing:\n",
        "    gen_object = ImageDataGenerator(preprocessing_function=preporcssing)\n",
        "  else:\n",
        "    gen_object = ImageDataGenerator()\n",
        "\n",
        "  return(gen_object.flow_from_directory(dir_path,\n",
        "                                        target_size=target_size,\n",
        "                                        batch_size=batch,\n",
        "                                        class_mode='sparse',\n",
        "                                        classes=class_lst,\n",
        "                                        shuffle=True))"
      ],
      "metadata": {
        "id": "Fhg3gCYrD_Xq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = img_Data(\"train\",(224,224),500,os.listdir(\"train\"),preprocess_input)\n",
        "valid_data_gen = img_Data(\"test\",(224,224),500,os.listdir(\"test\"),preprocess_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObjP1YW8GOdB",
        "outputId": "d70d86fe-3e69-4489-8f68-f16e99d0a2ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6912 images belonging to 10 classes.\n",
            "Found 2400 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "            input_shape=(224,224,3), alpha=1.0, include_top=False, weights='imagenet',\n",
        "            input_tensor=None, pooling=None, classes=1000,\n",
        "            classifier_activation='softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzD60LjAHB1c",
        "outputId": "3d4cdea4-e763-4889-e0cd-e4fc6618f94f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "_EkL9I3SHU2t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAvgPool2D())\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IRKQsFdLHazD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elst = callbacks.EarlyStopping(monitor='val_loss',patience=5,mode='min')\n",
        "save_ck = callbacks.ModelCheckpoint('.mdl_wt.hdf5',save_best_only=True,monitor='val_loss',mode='min')"
      ],
      "metadata": {
        "id": "QBAVsf7IH8uu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen,batch_size=500,validation_data=valid_data_gen,callbacks=[elst,save_ck],epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cCUeuxZJVQ0",
        "outputId": "ca780bac-7b0a-47dd-c56e-be5911de9aed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8537  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 3134s 227s/step - loss: 0.4582 - accuracy: 0.8537 - val_loss: 0.1455 - val_accuracy: 0.9546\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 64s 5s/step - loss: 0.1104 - accuracy: 0.9685 - val_loss: 0.1358 - val_accuracy: 0.9583\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 55s 4s/step - loss: 0.0701 - accuracy: 0.9777 - val_loss: 0.1296 - val_accuracy: 0.9608\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 53s 4s/step - loss: 0.0487 - accuracy: 0.9855 - val_loss: 0.1443 - val_accuracy: 0.9596\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 53s 4s/step - loss: 0.0335 - accuracy: 0.9918 - val_loss: 0.1324 - val_accuracy: 0.9629\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 54s 4s/step - loss: 0.0218 - accuracy: 0.9962 - val_loss: 0.1207 - val_accuracy: 0.9629\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 54s 4s/step - loss: 0.0152 - accuracy: 0.9986 - val_loss: 0.1194 - val_accuracy: 0.9642\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 54s 4s/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 0.1228 - val_accuracy: 0.9638\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 54s 4s/step - loss: 0.0099 - accuracy: 0.9996 - val_loss: 0.1390 - val_accuracy: 0.9608\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 54s 4s/step - loss: 0.0076 - accuracy: 0.9997 - val_loss: 0.1363 - val_accuracy: 0.9608\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf37b292020>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('.mdl_wt.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUlY-iTsYPoA",
        "outputId": "edac9024-509d-4c49-8088-a14dec6abd55"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}